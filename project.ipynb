{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "895a75fb",
   "metadata": {},
   "source": [
    "# INFO-f422: ML Project\n",
    "\n",
    "authors:\n",
    "+ 1 \n",
    "+ 2\n",
    "+ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dcc5fc",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "17578f83-f52e-47ee-9d73-b33d910722dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "from sklearn.linear_model import Ridge, Lasso, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.set_printoptions(threshold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493fe755",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ae6158-83fc-4039-ad35-4168b9fed8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "\n",
    "X_g_train = np.load(f\"{data_dir}/guided/guided_dataset_X.npy\")\n",
    "y_g_train = np.load(f\"{data_dir}/guided/guided_dataset_y.npy\")\n",
    "X_g_test = np.load(f\"{data_dir}/guided/guided_testset_X.npy\")\n",
    "\n",
    "X_f_train = np.load(f\"{data_dir}/freemoves/freemoves_dataset_X.npy\")\n",
    "y_f_train = np.load(f\"{data_dir}/freemoves/freemoves_dataset_y.npy\")\n",
    "X_f_test = np.load(f\"{data_dir}/freemoves/freemoves_testset_X.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5d74e88-bad4-4a00-9cdf-b5b5b1f6cfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guided:\n",
      "X_g_train (5, 8, 230000) / y_g_train(5, 51, 230000) / X_g_test(5, 332, 8, 500)\n",
      "\n",
      "Free moves:\n",
      "X_f_train(5, 8, 270000) / y_f_train(5, 51, 270000) / X_f_test(5, 308, 8, 500)\n"
     ]
    }
   ],
   "source": [
    "print(\"Guided:\")\n",
    "print(f\"X_g_train {X_g_train.shape} / y_g_train{y_g_train.shape} / X_g_test{X_g_test.shape}\\n\")\n",
    "print(\"Free moves:\")\n",
    "print(f\"X_f_train{X_f_train.shape} / y_f_train{y_f_train.shape} / X_f_test{X_f_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a29437e-9e32-45e1-a305-0bfad39af254",
   "metadata": {},
   "source": [
    "### 1) Signal filtering\n",
    "\n",
    "TODO: data exploration to take informed decision on filter (type of noise,....) to use and on filter parametres (no magic number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4331fabb-bc67-49c5-8d18-9572b5dc3e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, sosfiltfilt, firwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdf832f-16c7-4dbf-b0cc-43fc14aa64c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyq  = 1024 / 2\n",
    "low  = 20  / nyq\n",
    "high = 450 / nyq\n",
    "\n",
    "sos = butter(4,[low,high], btype='band', output= 'sos')\n",
    "\n",
    "for sess in range(X_g_train.shape[0]):\n",
    "    for elec in range(X_g_train.shape[1]):\n",
    "        # Application of the filtrage for x\n",
    "        X_g_train[sess, elec, :] = sosfiltfilt(sos, X_g_train[sess, elec, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1dfcb3-48a7-4df1-80ec-79e5fd3bd630",
   "metadata": {},
   "source": [
    "### 2) Dataset preparation\n",
    "\n",
    "For this question, we decided to use the sliding_window_view function from the Numpy library for several reasons:\n",
    "\n",
    "+ Fast vectorized numpy operations, compiled c-code (no python overhead, interpreter).\n",
    "\n",
    "+ sliding_window_view function returns a view, no copy.\n",
    "\n",
    "+ The function simplifies the implementation by automating window creation and indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74676a2-d393-4e44-98ce-48190ed197a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guided windowed:\n",
      "X_g_train_wdw (5, 919, 8, 500) / y_g_train_wdw(5, 919, 51) / X_g_test(5, 332, 8, 500)\n"
     ]
    }
   ],
   "source": [
    "def create_overlap_windows(x, y, window_size, overlap, axis):\n",
    "\n",
    "    step = int(window_size * (1 - overlap))\n",
    "\n",
    "    # sliding_windows_view Generate all possible windows with the corresponding step, that not what we want.\n",
    "    x_w = np.lib.stride_tricks.sliding_window_view(x,window_size,axis)\n",
    "    y_w = np.lib.stride_tricks.sliding_window_view(y,window_size,axis)\n",
    "\n",
    "    # only keep windows where the step is a multiple of our step \n",
    "    x_w = x_w[:,:,::step,:]\n",
    "    y_w = y_w[:,:,::step,:]\n",
    "\n",
    "    # We transpose the axes windows and electrode/signal \n",
    "    x_w = x_w.transpose(0, 2, 1, 3)     #  (session, window, electrode, time) and not  (session, electrode, window, time) TODO??\n",
    "    y_w = y_w.transpose(0, 2, 1, 3)     # (session, window, signals, time)\n",
    "\n",
    "    # Finaly, we keep only the last hand position (targets) for y, because for this project\n",
    "    # we need to predict, for each window in x, the final hand position in the\n",
    "    # same windows in the dataset y\n",
    "    y_w = y_w[..., -1]  # (sessions, windows, targets)\n",
    "\n",
    "    return x_w, y_w\n",
    "\n",
    "\n",
    "X_g_train_wdw, y_g_train_wdw = create_overlap_windows(X_g_train, y_g_train, window_size=500, overlap=0.5, axis=2)\n",
    "# !! windowed data is a view --> share original data memory (modify one, modify both)\n",
    "\n",
    "print(\"Guided windowed:\")\n",
    "print(f\"X_g_train_wdw {X_g_train_wdw.shape} / y_g_train_wdw{y_g_train_wdw.shape} / X_g_test{X_g_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a5557ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_windows_tests(x, y):\n",
    "    # (maybe automate tests given windowsize and overlap and consider internal frag (shoudl be discarded)\n",
    "    \n",
    "    x_w, y_w = create_overlap_windows(x, y, window_size=500, overlap=0.5, axis=2)    \n",
    "    \n",
    "    assert np.array_equal(x_w[0, 0, 0, :10], x[0, 0, :10]) # (sess 0) first 10 of electrode 0 in window 0\n",
    "    assert np.array_equal(x_w[0, 1, 0, :10], x[0, 0, 250:260]) # (sess 0) first 10 of electrode 0 in window 1\n",
    "    assert np.array_equal(x_w[0, 1, 4, :10], x[0, 4, 250:260]) # (sess 0) first 10 of electrode 4 in window 1\n",
    "    assert np.array_equal(x_w[0, 918, 0, -10:], x[0, 0, 229990:230000]) # (sess 0) last 10 of electrode 0 in last window (918) - (perfect fit!)\n",
    "\n",
    "quick_windows_tests(X_g_train, y_g_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efa6666-9c5a-422c-8c26-79b8f6594316",
   "metadata": {},
   "source": [
    "#### 3) Cross validation strategy\n",
    "\n",
    "For this question, we have thought about various methods of cross validation. First, our data are continous because it's a signal, so preserving temporal structure is important. We canâ€™t use a method of cross validation which randomly shuffles our windows. \n",
    "\n",
    "We also need to prevents data leaking so we can't use a methode who use the windows of one session for training AND validation because we have overlapping data in each session, two windows in the same session can share the same datas, and if these two windows are in train and validation, it will lead to data leakage and overly optimistic performance (data in the train set will also be in the validation set). \n",
    "\n",
    "So it's naturally that we have chosen the \"Leave One Group Out\" method, this method will use each session as the validation set once and the other for training. We completly prevent data leakage because each session is indepandent from the other, and we reduce the bias because each session will be used for validation.\n",
    "\n",
    "In our case, \"LOGO\" and \"GroupKFold(5)\" produce the same splits, but we choose \"LOGO\" because it's more explicit, readers will immediatly see that we use one session for validation each time while \"GroupKFold\" need to have 5 in parameter to do the same thong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d586a98-56d4-4372-a33f-01ba5ec537cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groups(4595,)\n",
      "\n",
      "Guided windowed flattened:\n",
      "X_g_train_wdw_flat(4595, 4000) / y_g_train_wdw_flat(4595, 51)\n"
     ]
    }
   ],
   "source": [
    "x_shape = X_g_train_wdw.shape\n",
    "y_shape = y_g_train_wdw.shape\n",
    "\n",
    "groups = np.repeat(np.arange(1,x_shape[0]+1),x_shape[1] ) # 111 (919 times), 222 (919 times), ...\n",
    "print(f\"groups{groups.shape}\\n\")\n",
    "\n",
    "# We need to flatten the dataset x and y because the function logo (and latter \"croos_val_score\"\n",
    "# want all the data in a 2d list, we will know have  the dataset X for exemple.\n",
    "# [4595, 4000] and not [5,919,8,500], 4595 is the multiplication of 5 and 919 (3500 = 8*500), and y \n",
    "# [4595,51] and not [5,919,51].\n",
    "# Now all the windows are store in a list and the \"groups\" list above allow the function \n",
    "# logo to know at wich session each windows belong\n",
    "# The windows 3 for example (x_windows_flat[2]) belong to the sessions groups[2] = 1\n",
    "X_g_train_wdw_flat = X_g_train_wdw.reshape(x_shape[0] * x_shape[1], x_shape[2] * x_shape[3])\n",
    "y_g_train_wdw_flat = y_g_train_wdw.reshape(y_shape[0] * y_shape[1], y_shape[2])\n",
    "\n",
    "print(\"Guided windowed flattened:\")\n",
    "print(f\"X_g_train_wdw_flat{X_g_train_wdw_flat.shape} / y_g_train_wdw_flat{y_g_train_wdw_flat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "80fae0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss functions/scorer\n",
    "def mse(y, y_hat):\n",
    "    return np.mean((y-y_hat)**2)\n",
    "\n",
    "def rmse(y, y_hat):\n",
    "    return np.sqrt(np.mean((y-y_hat)**2))\n",
    "\n",
    "def nmse(y, y_hat):\n",
    "    return np.mean((y-y_hat)**2)/np.std(y)**2\n",
    "\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "nmse_scorer = make_scorer(nmse, greater_is_better=False)\n",
    "\n",
    "# cv function (TODO: by hand ?)\n",
    "logo = LeaveOneGroupOut()\n",
    "def logo_cv(X, y, groups, model, scorer):\n",
    "    cv_scores = cross_val_score(model, X, y, groups=groups, cv=logo, scoring=scorer, n_jobs=-1) # n_jobs=-1 --> use all cores\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "# Lasso example\n",
    "# logo = LeaveOneGroupOut()\n",
    "# lasso_reg = Lasso(max_iter=1)\n",
    "# res = logo_cv(X_g_train_wdw_flat, y_g_train_wdw_flat, logo, groups, lasso_reg, rmse_scorer)\n",
    "# print(f\"cv score = {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1f1be5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (train_index, test_index) in enumerate(logo.split(X_g_train_wdw_flat, y_g_train_wdw_flat, groups)):\n",
    "#     print(f\"Fold {i}\")\n",
    "#     print(f\"   train groups: {np.unique(groups[train_index])}\")\n",
    "#     print(f\"   test groups: {np.unique(groups[test_index])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "384848b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rmse context\n",
    "# sess = 0\n",
    "# y_max = np.max(y_g_train_wdw[sess])\n",
    "# y_min = np.min(y_g_train_wdw[sess])\n",
    "# y_mean = np.mean(y_g_train_wdw[sess])\n",
    "\n",
    "# print(f\"Session {sess} target info:\\n  min = {y_min}\\n  max = {y_max}\\n  mean = {y_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d5e6b0",
   "metadata": {},
   "source": [
    "### 4) Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b57a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class TimeFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer that extracts common time-domain features:\n",
    "        - Mean Absolute Value (MAV)\n",
    "        - Root Mean Square (RMS)\n",
    "        - Variance\n",
    "        - Standard Deviation (STD)\n",
    "        - Zero Crossing (ZC)\n",
    "        - Myopulse Percentage Rate (MPR)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, threshold):\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        # TODO: all features/indicators\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57798424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score = -17.413224169467163\n"
     ]
    }
   ],
   "source": [
    "preprocess_pipe = Pipeline([\n",
    "    ('feat_extractor', TimeFeatureExtractor()),\n",
    "    # ('scaler', StandardScaler())\n",
    "    # TODO: other pre process steps ?\n",
    "])\n",
    "\n",
    "X_g_train_final = preprocess_pipe.fit(X_g_train_wdw, y_g_train_wdw)\n",
    "model = Lasso(max_iter=1)\n",
    "res = logo_cv(X_g_train_wdw_flat, y_g_train_wdw_flat, groups, model, rmse_scorer)\n",
    "print(f\"cv score = {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7d0ee8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {\n",
    "#     'logistic': LogisticRegression(),\n",
    "#     'lasso': Lasso(),\n",
    "#     'dec_tree': DecisionTreeRegressor(),\n",
    "#     'random_forest': RandomForestRegressor()\n",
    "# }\n",
    "\n",
    "# results = {}\n",
    "# for name, model in models.items():"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
