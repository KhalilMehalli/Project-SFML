{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "895a75fb",
   "metadata": {},
   "source": [
    "# INFO-f422: ML Project\n",
    "\n",
    "authors:\n",
    "+ 1 \n",
    "+ 2\n",
    "+ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dcc5fc",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17578f83-f52e-47ee-9d73-b33d910722dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "from sklearn.linear_model import Ridge, Lasso, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493fe755",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31ae6158-83fc-4039-ad35-4168b9fed8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "\n",
    "X_g_train = np.load(f\"{data_dir}/guided/guided_dataset_X.npy\")\n",
    "y_g_train = np.load(f\"{data_dir}/guided/guided_dataset_y.npy\")\n",
    "X_g_test = np.load(f\"{data_dir}/guided/guided_testset_X.npy\")\n",
    "\n",
    "X_f_train = np.load(f\"{data_dir}/freemoves/freemoves_dataset_X.npy\")\n",
    "y_f_train = np.load(f\"{data_dir}/freemoves/freemoves_dataset_y.npy\")\n",
    "X_f_test = np.load(f\"{data_dir}/freemoves/freemoves_testset_X.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5d74e88-bad4-4a00-9cdf-b5b5b1f6cfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guided:\n",
      "X_g_train (5, 8, 230000) / y_g_train(5, 51, 230000) / X_g_test(5, 332, 8, 500)\n",
      "\n",
      "Free moves:\n",
      "X_f_train(5, 8, 270000) / y_f_train(5, 51, 270000) / X_f_test(5, 308, 8, 500)\n"
     ]
    }
   ],
   "source": [
    "print(\"Guided:\")\n",
    "print(f\"X_g_train {X_g_train.shape} / y_g_train{y_g_train.shape} / X_g_test{X_g_test.shape}\\n\")\n",
    "print(\"Free moves:\")\n",
    "print(f\"X_f_train{X_f_train.shape} / y_f_train{y_f_train.shape} / X_f_test{X_f_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a29437e-9e32-45e1-a305-0bfad39af254",
   "metadata": {},
   "source": [
    "### 1) Signal filtering\n",
    "\n",
    "TODO: data exploration to take informed decision on filter (type of noise,....) to use and on filter parametres (no magic number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6bdf832f-16c7-4dbf-b0cc-43fc14aa64c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import butter, sosfiltfilt, firwin\n",
    "\n",
    "# nyq  = 1024 / 2\n",
    "# low  = 20  / nyq\n",
    "# high = 450 / nyq\n",
    "\n",
    "# sos = butter(4,[low,high], btype='band', output= 'sos')\n",
    "\n",
    "# for sess in range(X_g_train.shape[0]):\n",
    "#     for elec in range(X_g_train.shape[1]):\n",
    "#         # Application of the filtrage for x\n",
    "#         X_g_train[sess, elec, :] = sosfiltfilt(sos, X_g_train[sess, elec, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1dfcb3-48a7-4df1-80ec-79e5fd3bd630",
   "metadata": {},
   "source": [
    "### 2) Dataset preparation\n",
    "\n",
    "For this question, we decided to use the sliding_window_view function from the Numpy library for several reasons:\n",
    "\n",
    "+ Fast vectorized numpy operations, compiled c-code (no python overhead, interpreter).\n",
    "\n",
    "+ sliding_window_view function returns a view, no copy.\n",
    "\n",
    "+ The function simplifies the implementation by automating window creation and indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d522a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureWindowAugment(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    + Augment X through overlapping windows\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, window_size=500, overlap=0.5):\n",
    "        self.window_size = window_size\n",
    "        self.overlap = overlap\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        axis = 2 # time\n",
    "        step = int(self.window_size * (1 - self.overlap))\n",
    "        \n",
    "        # sliding_windows_view Generate all possible windows with the corresponding step, that not what we want.\n",
    "        X_windows = np.lib.stride_tricks.sliding_window_view(X,self.window_size, axis)\n",
    "\n",
    "        # only keep windows where the step is a multiple of our step \n",
    "        X_windows = X_windows[:,:,::step,:]\n",
    "         \n",
    "        # (session, electrode, window, time) to (session, window, electrode, time)\n",
    "        X_windows = X_windows.transpose(0, 2, 1, 3) \n",
    "        \n",
    "        return X_windows   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f74676a2-d393-4e44-98ce-48190ed197a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetStrategy(Enum):\n",
    "    \"\"\"\n",
    "    strategy to select the target (unique hand pose) from a window\n",
    "    \"\"\"\n",
    "    \n",
    "    MEAN = 0\n",
    "    FIRST = 1\n",
    "    LAST = 2\n",
    "    MEDIAN = 3\n",
    "    \n",
    "class WindowTargetExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    + augment y through overlapping windows \n",
    "    + extract the target, i.e. unique hand pose (51 val) of the correspondoing window (500 'samples')\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, window_size=500, overlap=0.5, target_strat=TargetStrategy.LAST):\n",
    "        self.window_size = window_size\n",
    "        self.overlap = overlap\n",
    "        self.target_strat = target_strat\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, y):\n",
    "        axis = 2 # time\n",
    "        step = int(self.window_size * (1 - self.overlap))\n",
    "        \n",
    "        # ----- window augment -----\n",
    "        \n",
    "        # sliding_windows_view Generate all possible windows with the corresponding step, that not what we want.\n",
    "        y_windows = np.lib.stride_tricks.sliding_window_view(y,self.window_size, axis)\n",
    "\n",
    "        # only keep windows where the step is a multiple of our step \n",
    "        y_windows = y_windows[:,:,::step,:]\n",
    "         \n",
    "        # (session, angles, window, time) to (session, window, angles, time)\n",
    "        y_windows = y_windows.transpose(0, 2, 1, 3)     \n",
    "        \n",
    "        # ----- target extract -----\n",
    "\n",
    "        match self.target_strat:\n",
    "            case TargetStrategy.LAST:\n",
    "                y_windows = y_windows[:, :, :, -1]\n",
    "            case TargetStrategy.FIRST:\n",
    "                y_windows = y_windows[:, :, :, 0]\n",
    "            case TargetStrategy.MEAN:\n",
    "                y_windows = np.mean(y_windows, axis=3)\n",
    "            case TargetStrategy.MEDIAN:\n",
    "                y_windows = np.median(y_windows, axis=3)\n",
    "            case _:\n",
    "                raise ValueError(f\"Unknown TargetStrategy enum value\")\n",
    "\n",
    "        return y_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cee174b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Extracts common time-domain features:\n",
    "        - Mean Absolute Value (MAV)\n",
    "        - Root Mean Square (RMS)\n",
    "        - Variance\n",
    "        - Standard Deviation (STD)\n",
    "        - Zero Crossing (ZC)\n",
    "        - Myopulse Percentage Rate (MPR)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, threshold=10):\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        # TODO: all features/indicators\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "749bb58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_g_train_final(5, 919, 8, 500) / y_g_train_final(5, 919, 51)\n"
     ]
    }
   ],
   "source": [
    "X_pipeline = Pipeline([\n",
    "    ('window_extractor', FeatureWindowAugment()),\n",
    "    ('feat_extractor', TimeFeatureExtractor()),\n",
    "    # ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "y_pipeline = WindowTargetExtractor()\n",
    "\n",
    "X_g_train_final = X_pipeline.fit_transform(X_g_train)\n",
    "y_g_train_final = y_pipeline.fit_transform(y_g_train)\n",
    "\n",
    "print(f\"X_g_train_final{X_g_train_final.shape} / y_g_train_final{y_g_train_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8a3e8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(X_g_train_final[0, 0, 0, :10], X_g_train[0, 0, :10]) # (sess 0) first 10 of electrode 0 in window 0\n",
    "assert np.array_equal(X_g_train_final[0, 1, 0, :10], X_g_train[0, 0, 250:260]) # (sess 0) first 10 of electrode 0 in window 1\n",
    "assert np.array_equal(X_g_train_final[0, 1, 4, :10], X_g_train[0, 4, 250:260]) # (sess 0) first 10 of electrode 4 in window 1\n",
    "assert np.array_equal(X_g_train_final[0, 918, 0, -10:], X_g_train[0, 0, 229990:230000]) # (sess 0) last 10 of electrode 0 in last window (918) - (perfect fit!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efa6666-9c5a-422c-8c26-79b8f6594316",
   "metadata": {},
   "source": [
    "#### 3) Cross validation strategy\n",
    "\n",
    "For this question, we have thought about various methods of cross validation. First, our data are continous because it's a signal, so preserving temporal structure is important. We can’t use a method of cross validation which randomly shuffles our windows. \n",
    "\n",
    "We also need to prevents data leaking so we can't use a methode who use the windows of one session for training AND validation because we have overlapping data in each session, two windows in the same session can share the same datas, and if these two windows are in train and validation, it will lead to data leakage and overly optimistic performance (data in the train set will also be in the validation set). \n",
    "\n",
    "So it's naturally that we have chosen the \"Leave One Group Out\" method, this method will use each session as the validation set once and the other for training. We completly prevent data leakage because each session is indepandent from the other, and we reduce the bias because each session will be used for validation.\n",
    "\n",
    "In our case, \"LOGO\" and \"GroupKFold(5)\" produce the same splits, but we choose \"LOGO\" because it's more explicit, readers will immediatly see that we use one session for validation each time while \"GroupKFold\" need to have 5 in parameter to do the same thong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d586a98-56d4-4372-a33f-01ba5ec537cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groups(4595,)\n",
      "\n",
      "Guided windowed flattened:\n",
      "X_g_train_wdw_flat(4595, 4000) / y_g_train_wdw_flat(4595, 51)\n"
     ]
    }
   ],
   "source": [
    "x_shape = X_g_train_wdw.shape\n",
    "y_shape = y_g_train_wdw.shape\n",
    "\n",
    "groups = np.repeat(np.arange(1,x_shape[0]+1),x_shape[1] ) # 111 (919 times), 222 (919 times), ...\n",
    "print(f\"groups{groups.shape}\\n\")\n",
    "\n",
    "# We need to flatten the dataset x and y because the function logo (and latter \"croos_val_score\"\n",
    "# want all the data in a 2d list, we will know have  the dataset X for exemple.\n",
    "# [4595, 4000] and not [5,919,8,500], 4595 is the multiplication of 5 and 919 (3500 = 8*500), and y \n",
    "# [4595,51] and not [5,919,51].\n",
    "# Now all the windows are store in a list and the \"groups\" list above allow the function \n",
    "# logo to know at wich session each windows belong\n",
    "# The windows 3 for example (x_windows_flat[2]) belong to the sessions groups[2] = 1\n",
    "X_g_train_wdw_flat = X_g_train_wdw.reshape(x_shape[0] * x_shape[1], x_shape[2] * x_shape[3])\n",
    "y_g_train_wdw_flat = y_g_train_wdw.reshape(y_shape[0] * y_shape[1], y_shape[2])\n",
    "\n",
    "print(\"Guided windowed flattened:\")\n",
    "print(f\"X_g_train_wdw_flat{X_g_train_wdw_flat.shape} / y_g_train_wdw_flat{y_g_train_wdw_flat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "80fae0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss functions/scorer\n",
    "def mse(y, y_hat):\n",
    "    return np.mean((y-y_hat)**2)\n",
    "\n",
    "def rmse(y, y_hat):\n",
    "    return np.sqrt(np.mean((y-y_hat)**2))\n",
    "\n",
    "def nmse(y, y_hat):\n",
    "    return np.mean((y-y_hat)**2)/np.std(y)**2\n",
    "\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "nmse_scorer = make_scorer(nmse, greater_is_better=False)\n",
    "\n",
    "# cv function (TODO: by hand ?)\n",
    "logo = LeaveOneGroupOut()\n",
    "def logo_cv(X, y, groups, model, scorer):\n",
    "    cv_scores = cross_val_score(model, X, y, groups=groups, cv=logo, scoring=scorer, n_jobs=-1) # n_jobs=-1 --> use all cores\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "# Lasso example\n",
    "# logo = LeaveOneGroupOut()\n",
    "# lasso_reg = Lasso(max_iter=1)\n",
    "# res = logo_cv(X_g_train_wdw_flat, y_g_train_wdw_flat, logo, groups, lasso_reg, rmse_scorer)\n",
    "# print(f\"cv score = {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1f1be5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (train_index, test_index) in enumerate(logo.split(X_g_train_wdw_flat, y_g_train_wdw_flat, groups)):\n",
    "#     print(f\"Fold {i}\")\n",
    "#     print(f\"   train groups: {np.unique(groups[train_index])}\")\n",
    "#     print(f\"   test groups: {np.unique(groups[test_index])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d5e6b0",
   "metadata": {},
   "source": [
    "### 4) Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0ee8c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4041499946.py, line 11)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmodel.\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'logistic': LogisticRegression(),\n",
    "    'lasso': Lasso(),\n",
    "    'dec_tree': DecisionTreeRegressor(),\n",
    "    'random_forest': RandomForestRegressor()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    \n",
    "    model.fit(X_g_train_final, y_g_train_final)\n",
    "    y_g_pred = model.predict(X_g_test) # transform X_g_test ??\n",
    "    \n",
    "    # logo cv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
